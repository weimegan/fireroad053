{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FireRoad053 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: thread = 1 warning: only found 11 / 12 columns around data row: 7. Filling remaining columns with `missing`\n",
      "└ @ CSV /Users/apple/.julia/packages/CSV/CJfFO/src/file.jl:605\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>student</th><th>semester</th><th>major</th><th>minor</th><th>s1_classes</th><th>s2_classes</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Date…</th><th>Int64?</th><th>String</th><th>String?</th></tr></thead><tbody><p>6 rows × 12 columns (omitted printing of 6 columns)</p><tr><th>1</th><td>1</td><td>1</td><td>0006-03-01</td><td><em>missing</em></td><td>[15, 16, 1, 3, 7]</td><td><em>missing</em></td></tr><tr><th>2</th><td>2</td><td>3</td><td>0006-03-01</td><td><em>missing</em></td><td>[15, 16, 3, 1, 5]</td><td>[20, 27, 2, 4, 42]</td></tr><tr><th>3</th><td>3</td><td>5</td><td>0006-03-01</td><td><em>missing</em></td><td>[15, 1, 3, 42]</td><td>[25, 20, 2, 4, 27]</td></tr><tr><th>4</th><td>4</td><td>1</td><td>0015-02-01</td><td>5</td><td>[1, 3, 36, 42]</td><td><em>missing</em></td></tr><tr><th>5</th><td>5</td><td>3</td><td>0015-02-01</td><td>5</td><td>[15, 16, 42, 3, 5]</td><td>[8, 36, 3, 32, 43]</td></tr><tr><th>6</th><td>6</td><td>5</td><td>0015-02-01</td><td>5</td><td>[3, 15, 16, 8, 42]</td><td>[32, 4, 10, 43]</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& student & semester & major & minor & s1\\_classes & s2\\_classes & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Date… & Int64? & String & String? & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 0006-03-01 & \\emph{missing} & [15, 16, 1, 3, 7] & \\emph{missing} & $\\dots$ \\\\\n",
       "\t2 & 2 & 3 & 0006-03-01 & \\emph{missing} & [15, 16, 3, 1, 5] & [20, 27, 2, 4, 42] & $\\dots$ \\\\\n",
       "\t3 & 3 & 5 & 0006-03-01 & \\emph{missing} & [15, 1, 3, 42] & [25, 20, 2, 4, 27] & $\\dots$ \\\\\n",
       "\t4 & 4 & 1 & 0015-02-01 & 5 & [1, 3, 36, 42] & \\emph{missing} & $\\dots$ \\\\\n",
       "\t5 & 5 & 3 & 0015-02-01 & 5 & [15, 16, 42, 3, 5] & [8, 36, 3, 32, 43] & $\\dots$ \\\\\n",
       "\t6 & 6 & 5 & 0015-02-01 & 5 & [3, 15, 16, 8, 42] & [32, 4, 10, 43] & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m6×12 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m student \u001b[0m\u001b[1m semester \u001b[0m\u001b[1m major      \u001b[0m\u001b[1m minor   \u001b[0m\u001b[1m s1_classes         \u001b[0m\u001b[1m s2_classes \u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64   \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Date…      \u001b[0m\u001b[90m Int64?  \u001b[0m\u001b[90m String             \u001b[0m\u001b[90m String?    \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │       1         1  0006-03-01 \u001b[90m missing \u001b[0m [15, 16, 1, 3, 7]  \u001b[90m missing    \u001b[0m ⋯\n",
       "   2 │       2         3  0006-03-01 \u001b[90m missing \u001b[0m [15, 16, 3, 1, 5]   [20, 27, 2,\n",
       "   3 │       3         5  0006-03-01 \u001b[90m missing \u001b[0m [15, 1, 3, 42]      [25, 20, 2,\n",
       "   4 │       4         1  0015-02-01        5  [1, 3, 36, 42]     \u001b[90m missing\u001b[0m\n",
       "   5 │       5         3  0015-02-01        5  [15, 16, 42, 3, 5]  [8, 36, 3,  ⋯\n",
       "   6 │       6         5  0015-02-01        5  [3, 15, 16, 8, 42]  [32, 4, 10,\n",
       "\u001b[36m                                                               7 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## if you have not installed package \"CSV\" or \"JSON\", please uncomment the line below and execute it\n",
    "# using Pkg; Pkg.add(\"CSV\")\n",
    "\n",
    "using DataFrames, CSV\n",
    "students = CSV.read(\"finaldata/students_data.csv\", DataFrame)\n",
    "reqs = CSV.read(\"finaldata/REQ.csv\", DataFrame)\n",
    "reqnots = CSV.read(\"finaldata/REQNOT.csv\", DataFrame)\n",
    "reqsems = CSV.read(\"finaldata/REQSEM.csv\", DataFrame)\n",
    "classes = CSV.read(\"finaldata/parsedsp21_actual_classes.csv\", DataFrame)\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91msyntax: incomplete: invalid string syntax\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91msyntax: incomplete: invalid string syntax\u001b[39m",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[58]:13",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "#classes[!,\"sections\"][3]\n",
    "using JSON\n",
    "classesjson = JSON.parsefile(\"finaldata/parsedsp21_dummy.json\") \n",
    "# one sefinaldata/parsedsp21_actual_classes\n",
    "sections = [\"LectureSession\", \"RecitationSession\", \"LabSession\"]\n",
    "\n",
    "# for class in keys(classesjson)\n",
    "#     for section in keys(classesjson[class][\"sections\"])\n",
    "#         print(classesjson[class][\"sections\"][section])\n",
    "#     end\n",
    "# end\n",
    "\n",
    "classesjson[\"6.006\"][\"sections\"][\"RecitationSession”]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Any,1}:\n",
       " Dict{String,Any}(\"s7_classes\" => Any[],\"s6_classes\" => Any[],\"s3_classes\" => Any[],\"minor\" => \"\",\"major\" => \"6-3\",\"s8_classes\" => Any[],\"s5_classes\" => Any[],\"semester\" => \"1\",\"student\" => \"1\",\"s1_classes\" => Any[15, 16, 1, 3, 7]…)\n",
       " Dict{String,Any}(\"s7_classes\" => Any[],\"s6_classes\" => Any[],\"s3_classes\" => Any[25, 18, 8, 43, 44],\"minor\" => \"\",\"major\" => \"6-3\",\"s8_classes\" => Any[],\"s5_classes\" => Any[],\"semester\" => \"3\",\"student\" => \"2\",\"s1_classes\" => Any[15, 16, 3, 1, 5]…)\n",
       " Dict{String,Any}(\"s7_classes\" => Any[],\"s6_classes\" => Any[],\"s3_classes\" => Any[19, 22, 43, 5],\"minor\" => \"\",\"major\" => \"6-3\",\"s8_classes\" => Any[],\"s5_classes\" => Any[45, 18, 46, 30],\"semester\" => \"5\",\"student\" => \"3\",\"s1_classes\" => Any[15, 1, 3, 42]…)\n",
       " Dict{String,Any}(\"s7_classes\" => Any[],\"s6_classes\" => Any[],\"s3_classes\" => Any[],\"minor\" => \"5\",\"major\" => \"15-2\",\"s8_classes\" => Any[],\"s5_classes\" => Any[],\"semester\" => \"1\",\"student\" => \"4\",\"s1_classes\" => Any[1, 3, 36, 42]…)\n",
       " Dict{String,Any}(\"s7_classes\" => Any[],\"s6_classes\" => Any[],\"s3_classes\" => Any[10, 35, 39, 44],\"minor\" => \"5\",\"major\" => \"15-2\",\"s8_classes\" => Any[],\"s5_classes\" => Any[],\"semester\" => \"3\",\"student\" => \"5\",\"s1_classes\" => Any[15, 16, 42, 3, 5]…)\n",
       " Dict{String,Any}(\"s7_classes\" => Any[],\"s6_classes\" => Any[],\"s3_classes\" => Any[40, 35, 11, 1, 44],\"minor\" => \"5\",\"major\" => \"15-2\",\"s8_classes\" => Any[],\"s5_classes\" => Any[37, 9, 39, 45],\"semester\" => \"5\",\"student\" => \"6\",\"s1_classes\" => Any[3, 15, 16, 8, 42]…)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentdata = JSON.parsefile(\"finaldata/students_data.json\")\n",
    "studentdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'LectureSession': [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]]}\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_more_sections = CSV.read(\"finaldata/parsedclasses.csv\", DataFrame)\n",
    "classes_more_sections[1, \"sections\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2021-07-07\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$ 5.4 x_{1,1} + 5.4 x_{1,2} + 5.4 x_{1,3} + 5.4 x_{1,4} + 5.4 x_{1,5} + 5.4 x_{1,6} + 5.4 x_{1,7} + 5.4 x_{1,8} + 5.3 x_{2,1} + 5.3 x_{2,2} + 5.3 x_{2,3} + 5.3 x_{2,4} + 5.3 x_{2,5} + 5.3 x_{2,6} + 5.3 x_{2,7} + 5.3 x_{2,8} + 4.3 x_{3,1} + 4.3 x_{3,2} + 4.3 x_{3,3} + 4.3 x_{3,4} + 4.3 x_{3,5} + 4.3 x_{3,6} + 4.3 x_{3,7} + 4.3 x_{3,8} + 5.9 x_{4,1} + 5.9 x_{4,2} + 5.9 x_{4,3} + 5.9 x_{4,4} + 5.9 x_{4,5} + 5.9 x_{4,6} + 5.9 x_{4,7} + 5.9 x_{4,8} + 4.3 x_{5,1} + 4.3 x_{5,2} + 4.3 x_{5,3} + 4.3 x_{5,4} + 4.3 x_{5,5} + 4.3 x_{5,6} + 4.3 x_{5,7} + 4.3 x_{5,8} + 5.5 x_{6,1} + 5.5 x_{6,2} + 5.5 x_{6,3} + 5.5 x_{6,4} + 5.5 x_{6,5} + 5.5 x_{6,6} + 5.5 x_{6,7} + 5.5 x_{6,8} + 5.7 x_{7,1} + 5.7 x_{7,2} + 5.7 x_{7,3} + 5.7 x_{7,4} + 5.7 x_{7,5} + 5.7 x_{7,6} + 5.7 x_{7,7} + 5.7 x_{7,8} + 5 x_{8,1} + 5 x_{8,2} + 5 x_{8,3} + 5 x_{8,4} + 5 x_{8,5} + 5 x_{8,6} + 5 x_{8,7} + 5 x_{8,8} + 5.1 x_{9,1} + 5.1 x_{9,2} + 5.1 x_{9,3} + 5.1 x_{9,4} + 5.1 x_{9,5} + 5.1 x_{9,6} + 5.1 x_{9,7} + 5.1 x_{9,8} + 5 x_{10,1} + 5 x_{10,2} + 5 x_{10,3} + 5 x_{10,4} + 5 x_{10,5} + 5 x_{10,6} + 5 x_{10,7} + 5 x_{10,8} + 6 x_{11,1} + 6 x_{11,2} + 6 x_{11,3} + 6 x_{11,4} + 6 x_{11,5} + 6 x_{11,6} + 6 x_{11,7} + 6 x_{11,8} + 5.7 x_{12,1} + 5.7 x_{12,2} + 5.7 x_{12,3} + 5.7 x_{12,4} + 5.7 x_{12,5} + 5.7 x_{12,6} + 5.7 x_{12,7} + 5.7 x_{12,8} + 5.6 x_{13,1} + 5.6 x_{13,2} + 5.6 x_{13,3} + 5.6 x_{13,4} + 5.6 x_{13,5} + 5.6 x_{13,6} + 5.6 x_{13,7} + 5.6 x_{13,8} + 3.3 x_{14,1} + 3.3 x_{14,2} + 3.3 x_{14,3} + 3.3 x_{14,4} + 3.3 x_{14,5} + 3.3 x_{14,6} + 3.3 x_{14,7} + 3.3 x_{14,8} + 5.4 x_{15,1} + 5.4 x_{15,2} + 5.4 x_{15,3} + 5.4 x_{15,4} + 5.4 x_{15,5} + 5.4 x_{15,6} + 5.4 x_{15,7} + 5.4 x_{15,8} + 5.3 x_{16,1} + 5.3 x_{16,2} + 5.3 x_{16,3} + 5.3 x_{16,4} + 5.3 x_{16,5} + 5.3 x_{16,6} + 5.3 x_{16,7} + 5.3 x_{16,8} + 5.2 x_{17,1} + 5.2 x_{17,2} + 5.2 x_{17,3} + 5.2 x_{17,4} + 5.2 x_{17,5} + 5.2 x_{17,6} + 5.2 x_{17,7} + 5.2 x_{17,8} + 5.3 x_{18,1} + 5.3 x_{18,2} + 5.3 x_{18,3} + 5.3 x_{18,4} + 5.3 x_{18,5} + 5.3 x_{18,6} + 5.3 x_{18,7} + 5.3 x_{18,8} + 6 x_{19,1} + 6 x_{19,2} + 6 x_{19,3} + 6 x_{19,4} + 6 x_{19,5} + 6 x_{19,6} + 6 x_{19,7} + 6 x_{19,8} + 5.6 x_{20,1} + 5.6 x_{20,2} + 5.6 x_{20,3} + 5.6 x_{20,4} + 5.6 x_{20,5} + 5.6 x_{20,6} + 5.6 x_{20,7} + 5.6 x_{20,8} + 5.9 x_{21,1} + 5.9 x_{21,2} + 5.9 x_{21,3} + 5.9 x_{21,4} + 5.9 x_{21,5} + 5.9 x_{21,6} + 5.9 x_{21,7} + 5.9 x_{21,8} + 5.5 x_{22,1} + 5.5 x_{22,2} + 5.5 x_{22,3} + 5.5 x_{22,4} + 5.5 x_{22,5} + 5.5 x_{22,6} + 5.5 x_{22,7} + 5.5 x_{22,8} + 5.1 x_{23,1} + 5.1 x_{23,2} + 5.1 x_{23,3} + 5.1 x_{23,4} + 5.1 x_{23,5} + 5.1 x_{23,6} + 5.1 x_{23,7} + 5.1 x_{23,8} + 5.5 x_{24,1} + 5.5 x_{24,2} + 5.5 x_{24,3} + 5.5 x_{24,4} + 5.5 x_{24,5} + 5.5 x_{24,6} + 5.5 x_{24,7} + 5.5 x_{24,8} + 5 x_{25,1} + 5 x_{25,2} + 5 x_{25,3} + 5 x_{25,4} + 5 x_{25,5} + 5 x_{25,6} + 5 x_{25,7} + 5 x_{25,8} + 5.4 x_{26,1} + 5.4 x_{26,2} + 5.4 x_{26,3} + 5.4 x_{26,4} + 5.4 x_{26,5} + 5.4 x_{26,6} + 5.4 x_{26,7} + 5.4 x_{26,8} + 6.6 x_{27,1} + 6.6 x_{27,2} + 6.6 x_{27,3} + 6.6 x_{27,4} + 6.6 x_{27,5} + 6.6 x_{27,6} + 6.6 x_{27,7} + 6.6 x_{27,8} + 5.4 x_{28,1} + 5.4 x_{28,2} + 5.4 x_{28,3} + 5.4 x_{28,4} + 5.4 x_{28,5} + 5.4 x_{28,6} + 5.4 x_{28,7} + 5.4 x_{28,8} + 5 x_{29,1} + 5 x_{29,2} + 5 x_{29,3} + 5 x_{29,4} + 5 x_{29,5} + 5 x_{29,6} + 5 x_{29,7} + 5 x_{29,8} + 5.5 x_{30,1} + 5.5 x_{30,2} + 5.5 x_{30,3} + 5.5 x_{30,4} + 5.5 x_{30,5} + 5.5 x_{30,6} + 5.5 x_{30,7} + 5.5 x_{30,8} + 5.8 x_{31,1} + 5.8 x_{31,2} + 5.8 x_{31,3} + 5.8 x_{31,4} + 5.8 x_{31,5} + 5.8 x_{31,6} + 5.8 x_{31,7} + 5.8 x_{31,8} + 6.1 x_{32,1} + 6.1 x_{32,2} + 6.1 x_{32,3} + 6.1 x_{32,4} + 6.1 x_{32,5} + 6.1 x_{32,6} + 6.1 x_{32,7} + 6.1 x_{32,8} + 6 x_{33,1} + 6 x_{33,2} + 6 x_{33,3} + 6 x_{33,4} + 6 x_{33,5} + 6 x_{33,6} + 6 x_{33,7} + 6 x_{33,8} + 6.1 x_{34,1} + 6.1 x_{34,2} + 6.1 x_{34,3} + 6.1 x_{34,4} + 6.1 x_{34,5} + 6.1 x_{34,6} + 6.1 x_{34,7} + 6.1 x_{34,8} + 6.2 x_{35,1} + 6.2 x_{35,2} + 6.2 x_{35,3} + 6.2 x_{35,4} + 6.2 x_{35,5} + 6.2 x_{35,6} + 6.2 x_{35,7} + 6.2 x_{35,8} + 5.9 x_{36,1} + 5.9 x_{36,2} + 5.9 x_{36,3} + 5.9 x_{36,4} + 5.9 x_{36,5} + 5.9 x_{36,6} + 5.9 x_{36,7} + 5.9 x_{36,8} + 6 x_{37,1} + 6 x_{37,2} + 6 x_{37,3} + 6 x_{37,4} + 6 x_{37,5} + 6 x_{37,6} + 6 x_{37,7} + 6 x_{37,8} + 6.6 x_{38,1} + 6.6 x_{38,2} + 6.6 x_{38,3} + 6.6 x_{38,4} + 6.6 x_{38,5} + 6.6 x_{38,6} + 6.6 x_{38,7} + 6.6 x_{38,8} + 4.8 x_{39,1} + 4.8 x_{39,2} + 4.8 x_{39,3} + 4.8 x_{39,4} + 4.8 x_{39,5} + 4.8 x_{39,6} + 4.8 x_{39,7} + 4.8 x_{39,8} + 6.2 x_{40,1} + 6.2 x_{40,2} + 6.2 x_{40,3} + 6.2 x_{40,4} + 6.2 x_{40,5} + 6.2 x_{40,6} + 6.2 x_{40,7} + 6.2 x_{40,8} + 5.5 x_{41,1} + 5.5 x_{41,2} + 5.5 x_{41,3} + 5.5 x_{41,4} + 5.5 x_{41,5} + 5.5 x_{41,6} + 5.5 x_{41,7} + 5.5 x_{41,8} + 6.3 x_{42,1} + 6.3 x_{42,2} + 6.3 x_{42,3} + 6.3 x_{42,4} + 6.3 x_{42,5} + 6.3 x_{42,6} + 6.3 x_{42,7} + 6.3 x_{42,8} + 6 x_{43,1} + 6 x_{43,2} + 6 x_{43,3} + 6 x_{43,4} + 6 x_{43,5} + 6 x_{43,6} + 6 x_{43,7} + 6 x_{43,8} + 7 x_{44,1} + 7 x_{44,2} + 7 x_{44,3} + 7 x_{44,4} + 7 x_{44,5} + 7 x_{44,6} + 7 x_{44,7} + 7 x_{44,8} + 6.9 x_{45,1} + 6.9 x_{45,2} + 6.9 x_{45,3} + 6.9 x_{45,4} + 6.9 x_{45,5} + 6.9 x_{45,6} + 6.9 x_{45,7} + 6.9 x_{45,8} + 5.1 x_{46,1} + 5.1 x_{46,2} + 5.1 x_{46,3} + 5.1 x_{46,4} + 5.1 x_{46,5} + 5.1 x_{46,6} + 5.1 x_{46,7} + 5.1 x_{46,8} + 6.5 x_{47,1} + 6.5 x_{47,2} + 6.5 x_{47,3} + 6.5 x_{47,4} + 6.5 x_{47,5} + 6.5 x_{47,6} + 6.5 x_{47,7} + 6.5 x_{47,8} + 6.5 x_{48,1} + 6.5 x_{48,2} + 6.5 x_{48,3} + 6.5 x_{48,4} + 6.5 x_{48,5} + 6.5 x_{48,6} + 6.5 x_{48,7} + 6.5 x_{48,8} + 6.3 x_{49,1} + 6.3 x_{49,2} + 6.3 x_{49,3} + 6.3 x_{49,4} + 6.3 x_{49,5} + 6.3 x_{49,6} + 6.3 x_{49,7} + 6.3 x_{49,8} + 5.4 x_{50,1} + 5.4 x_{50,2} + 5.4 x_{50,3} + 5.4 x_{50,4} + 5.4 x_{50,5} + 5.4 x_{50,6} + 5.4 x_{50,7} + 5.4 x_{50,8} $$"
      ],
      "text/plain": [
       "5.4 x[1,1] + 5.4 x[1,2] + 5.4 x[1,3] + 5.4 x[1,4] + 5.4 x[1,5] + 5.4 x[1,6] + 5.4 x[1,7] + 5.4 x[1,8] + 5.3 x[2,1] + 5.3 x[2,2] + 5.3 x[2,3] + 5.3 x[2,4] + 5.3 x[2,5] + 5.3 x[2,6] + 5.3 x[2,7] + 5.3 x[2,8] + 4.3 x[3,1] + 4.3 x[3,2] + 4.3 x[3,3] + 4.3 x[3,4] + 4.3 x[3,5] + 4.3 x[3,6] + 4.3 x[3,7] + 4.3 x[3,8] + 5.9 x[4,1] + 5.9 x[4,2] + 5.9 x[4,3] + 5.9 x[4,4] + 5.9 x[4,5] + 5.9 x[4,6] + 5.9 x[4,7] + 5.9 x[4,8] + 4.3 x[5,1] + 4.3 x[5,2] + 4.3 x[5,3] + 4.3 x[5,4] + 4.3 x[5,5] + 4.3 x[5,6] + 4.3 x[5,7] + 4.3 x[5,8] + 5.5 x[6,1] + 5.5 x[6,2] + 5.5 x[6,3] + 5.5 x[6,4] + 5.5 x[6,5] + 5.5 x[6,6] + 5.5 x[6,7] + 5.5 x[6,8] + 5.7 x[7,1] + 5.7 x[7,2] + 5.7 x[7,3] + 5.7 x[7,4] + 5.7 x[7,5] + 5.7 x[7,6] + 5.7 x[7,7] + 5.7 x[7,8] + 5 x[8,1] + 5 x[8,2] + 5 x[8,3] + 5 x[8,4] + 5 x[8,5] + 5 x[8,6] + 5 x[8,7] + 5 x[8,8] + 5.1 x[9,1] + 5.1 x[9,2] + 5.1 x[9,3] + 5.1 x[9,4] + 5.1 x[9,5] + 5.1 x[9,6] + 5.1 x[9,7] + 5.1 x[9,8] + 5 x[10,1] + 5 x[10,2] + 5 x[10,3] + 5 x[10,4] + 5 x[10,5] + 5 x[10,6] + 5 x[10,7] + 5 x[10,8] + 6 x[11,1] + 6 x[11,2] + 6 x[11,3] + 6 x[11,4] + 6 x[11,5] + 6 x[11,6] + 6 x[11,7] + 6 x[11,8] + 5.7 x[12,1] + 5.7 x[12,2] + 5.7 x[12,3] + 5.7 x[12,4] + 5.7 x[12,5] + 5.7 x[12,6] + 5.7 x[12,7] + 5.7 x[12,8] + 5.6 x[13,1] + 5.6 x[13,2] + 5.6 x[13,3] + 5.6 x[13,4] + 5.6 x[13,5] + 5.6 x[13,6] + 5.6 x[13,7] + 5.6 x[13,8] + 3.3 x[14,1] + 3.3 x[14,2] + 3.3 x[14,3] + 3.3 x[14,4] + 3.3 x[14,5] + 3.3 x[14,6] + 3.3 x[14,7] + 3.3 x[14,8] + 5.4 x[15,1] + 5.4 x[15,2] + 5.4 x[15,3] + 5.4 x[15,4] + 5.4 x[15,5] + 5.4 x[15,6] + 5.4 x[15,7] + 5.4 x[15,8] + 5.3 x[16,1] + 5.3 x[16,2] + 5.3 x[16,3] + 5.3 x[16,4] + 5.3 x[16,5] + 5.3 x[16,6] + 5.3 x[16,7] + 5.3 x[16,8] + 5.2 x[17,1] + 5.2 x[17,2] + 5.2 x[17,3] + 5.2 x[17,4] + 5.2 x[17,5] + 5.2 x[17,6] + 5.2 x[17,7] + 5.2 x[17,8] + 5.3 x[18,1] + 5.3 x[18,2] + 5.3 x[18,3] + 5.3 x[18,4] + 5.3 x[18,5] + 5.3 x[18,6] + 5.3 x[18,7] + 5.3 x[18,8] + 6 x[19,1] + 6 x[19,2] + 6 x[19,3] + 6 x[19,4] + 6 x[19,5] + 6 x[19,6] + 6 x[19,7] + 6 x[19,8] + 5.6 x[20,1] + 5.6 x[20,2] + 5.6 x[20,3] + 5.6 x[20,4] + 5.6 x[20,5] + 5.6 x[20,6] + 5.6 x[20,7] + 5.6 x[20,8] + 5.9 x[21,1] + 5.9 x[21,2] + 5.9 x[21,3] + 5.9 x[21,4] + 5.9 x[21,5] + 5.9 x[21,6] + 5.9 x[21,7] + 5.9 x[21,8] + 5.5 x[22,1] + 5.5 x[22,2] + 5.5 x[22,3] + 5.5 x[22,4] + 5.5 x[22,5] + 5.5 x[22,6] + 5.5 x[22,7] + 5.5 x[22,8] + 5.1 x[23,1] + 5.1 x[23,2] + 5.1 x[23,3] + 5.1 x[23,4] + 5.1 x[23,5] + 5.1 x[23,6] + 5.1 x[23,7] + 5.1 x[23,8] + 5.5 x[24,1] + 5.5 x[24,2] + 5.5 x[24,3] + 5.5 x[24,4] + 5.5 x[24,5] + 5.5 x[24,6] + 5.5 x[24,7] + 5.5 x[24,8] + 5 x[25,1] + 5 x[25,2] + 5 x[25,3] + 5 x[25,4] + 5 x[25,5] + 5 x[25,6] + 5 x[25,7] + 5 x[25,8] + 5.4 x[26,1] + 5.4 x[26,2] + 5.4 x[26,3] + 5.4 x[26,4] + 5.4 x[26,5] + 5.4 x[26,6] + 5.4 x[26,7] + 5.4 x[26,8] + 6.6 x[27,1] + 6.6 x[27,2] + 6.6 x[27,3] + 6.6 x[27,4] + 6.6 x[27,5] + 6.6 x[27,6] + 6.6 x[27,7] + 6.6 x[27,8] + 5.4 x[28,1] + 5.4 x[28,2] + 5.4 x[28,3] + 5.4 x[28,4] + 5.4 x[28,5] + 5.4 x[28,6] + 5.4 x[28,7] + 5.4 x[28,8] + 5 x[29,1] + 5 x[29,2] + 5 x[29,3] + 5 x[29,4] + 5 x[29,5] + 5 x[29,6] + 5 x[29,7] + 5 x[29,8] + 5.5 x[30,1] + 5.5 x[30,2] + 5.5 x[30,3] + 5.5 x[30,4] + 5.5 x[30,5] + 5.5 x[30,6] + 5.5 x[30,7] + 5.5 x[30,8] + 5.8 x[31,1] + 5.8 x[31,2] + 5.8 x[31,3] + 5.8 x[31,4] + 5.8 x[31,5] + 5.8 x[31,6] + 5.8 x[31,7] + 5.8 x[31,8] + 6.1 x[32,1] + 6.1 x[32,2] + 6.1 x[32,3] + 6.1 x[32,4] + 6.1 x[32,5] + 6.1 x[32,6] + 6.1 x[32,7] + 6.1 x[32,8] + 6 x[33,1] + 6 x[33,2] + 6 x[33,3] + 6 x[33,4] + 6 x[33,5] + 6 x[33,6] + 6 x[33,7] + 6 x[33,8] + 6.1 x[34,1] + 6.1 x[34,2] + 6.1 x[34,3] + 6.1 x[34,4] + 6.1 x[34,5] + 6.1 x[34,6] + 6.1 x[34,7] + 6.1 x[34,8] + 6.2 x[35,1] + 6.2 x[35,2] + 6.2 x[35,3] + 6.2 x[35,4] + 6.2 x[35,5] + 6.2 x[35,6] + 6.2 x[35,7] + 6.2 x[35,8] + 5.9 x[36,1] + 5.9 x[36,2] + 5.9 x[36,3] + 5.9 x[36,4] + 5.9 x[36,5] + 5.9 x[36,6] + 5.9 x[36,7] + 5.9 x[36,8] + 6 x[37,1] + 6 x[37,2] + 6 x[37,3] + 6 x[37,4] + 6 x[37,5] + 6 x[37,6] + 6 x[37,7] + 6 x[37,8] + 6.6 x[38,1] + 6.6 x[38,2] + 6.6 x[38,3] + 6.6 x[38,4] + 6.6 x[38,5] + 6.6 x[38,6] + 6.6 x[38,7] + 6.6 x[38,8] + 4.8 x[39,1] + 4.8 x[39,2] + 4.8 x[39,3] + 4.8 x[39,4] + 4.8 x[39,5] + 4.8 x[39,6] + 4.8 x[39,7] + 4.8 x[39,8] + 6.2 x[40,1] + 6.2 x[40,2] + 6.2 x[40,3] + 6.2 x[40,4] + 6.2 x[40,5] + 6.2 x[40,6] + 6.2 x[40,7] + 6.2 x[40,8] + 5.5 x[41,1] + 5.5 x[41,2] + 5.5 x[41,3] + 5.5 x[41,4] + 5.5 x[41,5] + 5.5 x[41,6] + 5.5 x[41,7] + 5.5 x[41,8] + 6.3 x[42,1] + 6.3 x[42,2] + 6.3 x[42,3] + 6.3 x[42,4] + 6.3 x[42,5] + 6.3 x[42,6] + 6.3 x[42,7] + 6.3 x[42,8] + 6 x[43,1] + 6 x[43,2] + 6 x[43,3] + 6 x[43,4] + 6 x[43,5] + 6 x[43,6] + 6 x[43,7] + 6 x[43,8] + 7 x[44,1] + 7 x[44,2] + 7 x[44,3] + 7 x[44,4] + 7 x[44,5] + 7 x[44,6] + 7 x[44,7] + 7 x[44,8] + 6.9 x[45,1] + 6.9 x[45,2] + 6.9 x[45,3] + 6.9 x[45,4] + 6.9 x[45,5] + 6.9 x[45,6] + 6.9 x[45,7] + 6.9 x[45,8] + 5.1 x[46,1] + 5.1 x[46,2] + 5.1 x[46,3] + 5.1 x[46,4] + 5.1 x[46,5] + 5.1 x[46,6] + 5.1 x[46,7] + 5.1 x[46,8] + 6.5 x[47,1] + 6.5 x[47,2] + 6.5 x[47,3] + 6.5 x[47,4] + 6.5 x[47,5] + 6.5 x[47,6] + 6.5 x[47,7] + 6.5 x[47,8] + 6.5 x[48,1] + 6.5 x[48,2] + 6.5 x[48,3] + 6.5 x[48,4] + 6.5 x[48,5] + 6.5 x[48,6] + 6.5 x[48,7] + 6.5 x[48,8] + 6.3 x[49,1] + 6.3 x[49,2] + 6.3 x[49,3] + 6.3 x[49,4] + 6.3 x[49,5] + 6.3 x[49,6] + 6.3 x[49,7] + 6.3 x[49,8] + 5.4 x[50,1] + 5.4 x[50,2] + 5.4 x[50,3] + 5.4 x[50,4] + 5.4 x[50,5] + 5.4 x[50,6] + 5.4 x[50,7] + 5.4 x[50,8]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--- Model specification\n",
    "using JuMP, DataFrames, Gurobi\n",
    "M = 1000000\n",
    "S = nrow(classes)\n",
    "T = 8\n",
    "min_units = 12 #change this for each student!\n",
    "max_units = 60 #change this for each student!\n",
    "min_workload = 40 #change this for each student!\n",
    "max_workload = 70 #change this for each student!\n",
    "\n",
    "model = Model(with_optimizer(Gurobi.Optimizer))\n",
    "\n",
    "@variable(model, x[1:S, 1:T], Bin)\n",
    "@objective(model, Max, sum(sum(x[s, t] for t = 1:T) * classes[s, 9] for s = 1:S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-dimensional DenseAxisArray{ConstraintRef{Model,C,Shape} where Shape<:AbstractShape where C,1,...} with index sets:\n",
       "    Dimension 1, [7, 22, 24, 28, 29, 30, 32, 33, 34, 39]\n",
       "And data, a 10-element Array{ConstraintRef{Model,C,Shape} where Shape<:AbstractShape where C,1}:\n",
       " spring_only[7] : x[7,1] + x[7,3] + x[7,5] + x[7,7] = 0.0\n",
       " spring_only[22] : x[22,1] + x[22,3] + x[22,5] + x[22,7] = 0.0\n",
       " spring_only[24] : x[24,1] + x[24,3] + x[24,5] + x[24,7] = 0.0\n",
       " spring_only[28] : x[28,1] + x[28,3] + x[28,5] + x[28,7] = 0.0\n",
       " spring_only[29] : x[29,1] + x[29,3] + x[29,5] + x[29,7] = 0.0\n",
       " spring_only[30] : x[30,1] + x[30,3] + x[30,5] + x[30,7] = 0.0\n",
       " spring_only[32] : x[32,1] + x[32,3] + x[32,5] + x[32,7] = 0.0\n",
       " spring_only[33] : x[33,1] + x[33,3] + x[33,5] + x[33,7] = 0.0\n",
       " spring_only[34] : x[34,1] + x[34,3] + x[34,5] + x[34,7] = 0.0\n",
       " spring_only[39] : x[39,1] + x[39,3] + x[39,5] + x[39,7] = 0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Each student takes (or gets credit for) all of the Science/Math GIRs.\n",
    "# Math GIR\n",
    "@constraint(model, math, sum(x[3, t] + x[4, t] for t = 1:T) == 1)\n",
    "\n",
    "# Physics GIR\n",
    "@constraint(model, physics, sum(x[1, t] + x[2, t] for t = 1:T) == 1)\n",
    "\n",
    "# Chemistry GIR\n",
    "@constraint(model, chem, sum(x[7, t] + x[8, t] for t = 1:T) == 1)\n",
    "\n",
    "# Biology GIR\n",
    "@constraint(model, bio, sum(x[5, t] + x[6, t] for t = 1:T) == 1)\n",
    "\n",
    "# 2. Each student takes 8 HASS subjects.\n",
    "@constraint(model, hass, sum(x[s, t] for s = 42:50 for t = 1:T) >= 8)\n",
    "\n",
    "# 3. Each student satisfies the requirements of her major (and minor).\n",
    "\n",
    "\n",
    "# 4. No subject is taken prior to its prerequisites.\n",
    "@constraint(model, prereq802[t in 2:T], sum(x[1, j] + x[3, j] for j in 1:t-1) >= 2 * x[2, t])\n",
    "@constraint(model, prereq1802[t in 2:T], sum(x[3, j] for j in 1:t-1) >= x[4, t])\n",
    "@constraint(model, prereq507[t in 2:T], sum(x[10, j] for j in 1:t-1) >= x[9, t])\n",
    "@constraint(model, prereq512[t in 2:T], sum(x[7, j] + x[8, j] for j in 1:t-1) >= x[10, t])\n",
    "@constraint(model, prereq513[t in 2:T], sum(x[10, j] for j in 1:t-1) >= x[11, t])\n",
    "@constraint(model, prereq5310[t in 2:T], sum(x[10, j] for j in 1:t-1) >= x[12, t])\n",
    "@constraint(model, prereq5601cal[t in 2:T], sum(x[4, j] for j in 1:t-1) >= x[13, t])\n",
    "@constraint(model, prereq5601chem[t in 2:T], sum(x[7, j] + x[8, j] for j in 1:t-1) >= x[13, t])\n",
    "@constraint(model, prereq5602[t in 2:T], sum(x[13, j] for j in 1:t-1) >= x[14, t])\n",
    "@constraint(model, prereq60002[t in 2:T], sum(x[15, j] for j in 1:t-1) >= x[16, t])\n",
    "@constraint(model, prereq6003[t in 2:T], sum(x[3, j] + x[15, j] for j in 1:t-1) >= 2 * x[17, t])\n",
    "@constraint(model, prereq6004[t in 2:T], sum(x[2, j] + x[15, j] for j in 1:t-1) >= 2 * x[18, t])\n",
    "@constraint(model, prereq6006a[t in 2:T], sum(x[25, j] for j in 1:t-1) >= x[19, t])\n",
    "@constraint(model, prereq6006b[t in 2:T], sum(x[15, j] + x[20, j] for j in 1:t-1) >= x[19, t])\n",
    "@constraint(model, prereq6009[t in 2:T], sum(x[15, j] for j in 1:t-1) >= x[20, t])\n",
    "@constraint(model, prereq603[t in 2:T], sum(x[2, j] + x[4, j] for j in 1:t-1) >= 2 * x[21, t])\n",
    "@constraint(model, prereq6031[t in 2:T], sum(x[20, j] for j in 1:t-1) >= x[22, t])\n",
    "@constraint(model, prereq6033[t in 2:T], sum(x[18, j] + x[20, j] for j in 1:t-1) >= 2 * x[23, t])\n",
    "@constraint(model, prereq6036[t in 2:T], sum(x[4, j] + x[15, j] for j in 1:t-1) >= 2 * x[24, t])\n",
    "@constraint(model, prereq6042[t in 2:T], sum(x[3, j] for j in 1:t-1) >= x[25, t])\n",
    "@constraint(model, prereq6046[t in 2:T], sum(x[19, j] for j in 1:t-1) >= x[26, t])\n",
    "@constraint(model, prereq608[t in 2:T], sum(x[2, j] + x[15, j] for j in 1:t-1) >= 2 * x[27, t])\n",
    "@constraint(model, prereq6806[t in 2:T], sum(x[26, j] for j in 1:t-1) >= x[28, t])\n",
    "@constraint(model, prereq6819[t in 2:T], sum(x[25, j] + x[39, j] for j in 1:t-1) >= 2 * x[29, t])\n",
    "@constraint(model, prereq150251[t in 2:T], sum(x[50, j] for j in 1:t-1) >= x[31, t])\n",
    "@constraint(model, prereq15053[t in 2:T], sum(x[15, j] for j in 1:t-1) >= x[32, t])\n",
    "@constraint(model, prereq1806[t in 2:T], sum(x[4, j] for j in 1:t-1) >= x[39, t])\n",
    "@constraint(model, prereq18600[t in 2:T], sum(x[4, j] for j in 1:t-1) >= x[40, t])\n",
    "@constraint(model, prereq18650[t in 2:T], sum(x[40, j] for j in 1:t-1) >= x[41, t])\n",
    "\n",
    "# 5. Each student takes 216 units beyond GIRs.\n",
    "@constraint(model, units, sum(x[s, t] * classes[s, 8] for s = 1:S for t = 1:T) >= 208)\n",
    "\n",
    "# 6. No two subjects taken in Spring 2021 should overlap in time.\n",
    "\n",
    "    \n",
    "# 7. Students cannot take the same subject twice.\n",
    "@constraint(model, once[s in 1:S], sum(x[s, t] for t = 1:T) <= 1)\n",
    "\n",
    "# 8. Each student can specify if they want to take a specific subject in the future.\n",
    "@constraint(model, req[s in 1:S], sum(x[s, t] for t in 1:T) >= 1 - M * (1 - reqs[s, 1]))\n",
    "\n",
    "# 9. Each student can specify which semester they want to take a subject.\n",
    "@constraint(model, reqsem[s in 1:S, t in 1:T], x[s, t] >= 1 - M * (1 - reqsems[s, t]))\n",
    "\n",
    "# 10. Each student can specify which semester they do not want to take a subject. \n",
    "@constraint(model, reqnot[s in 1:S, t in 1:T], x[s, t] <= 1 + M * (1 - reqnots[s, t]))\n",
    "    \n",
    "# 11. The minimum and maximum number of units that each student wants to take each semester.\n",
    "@constraint(model, minunits[t in 1:T], sum(x[s, t] * classes[s, 8] for s in 1:S) >= min_units)\n",
    "@constraint(model, maxunits[t in 1:T], sum(x[s, t] * classes[s, 8] for s in 1:S) <= max_units)\n",
    "    \n",
    "# 12. The minimum and maximum workload (in number of hours) that each student wants to take on each semester.\n",
    "@constraint(model, minwork[t in 1:T], sum(x[s, t] * classes[s, 10] for s in 1:S) >= min_workload)\n",
    "@constraint(model, maxwork[t in 1:T], sum(x[s, t] * classes[s, 10] for s in 1:S) <= max_workload)\n",
    "\n",
    "# 13. Restricts taking classes to the semester they're offered\n",
    "@constraint(model, fall_only[s in [1, 10, 12, 36, 38]], sum(x[s, t] for t in [2, 4, 6, 8]) == 0)\n",
    "@constraint(model, spring_only[s in [7, 22, 24, 28, 29, 30, 32, 33, 34, 39]], sum(x[s, t] for t in [1, 3, 5, 7]) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.1 build v9.1.1rc0 (mac64)\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "Optimize a model with 1156 rows, 400 columns and 5119 nonzeros\n",
      "Model fingerprint: 0x51c06ffd\n",
      "Variable types: 0 continuous, 400 integer (400 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+01]\n",
      "  Objective range  [3e+00, 7e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 1e+06]\n",
      "Presolve removed 974 rows and 122 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 182 rows, 278 columns, 2001 nonzeros\n",
      "Variable types: 0 continuous, 278 integer (278 binary)\n",
      "\n",
      "Root relaxation: objective 2.478500e+02, 226 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  247.85000    0   11          -  247.85000      -     -    0s\n",
      "H    0     0                     241.6000000  247.85000  2.59%     -    0s\n",
      "H    0     0                     241.8000000  247.85000  2.50%     -    0s\n",
      "H    0     0                     246.5000000  247.85000  0.55%     -    0s\n",
      "     0     0  247.08667    0   37  246.50000  247.08667  0.24%     -    0s\n",
      "H    0     0                     246.9000000  247.08667  0.08%     -    0s\n",
      "     0     0  247.00000    0   26  246.90000  247.00000  0.04%     -    0s\n",
      "     0     0  247.00000    0   16  246.90000  247.00000  0.04%     -    0s\n",
      "     0     0  247.00000    0   18  246.90000  247.00000  0.04%     -    0s\n",
      "     0     0 infeasible    0       246.90000  246.90000  0.00%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 6\n",
      "  Cover: 20\n",
      "  MIR: 3\n",
      "  StrongCG: 1\n",
      "  GUB cover: 7\n",
      "  Mod-K: 3\n",
      "  RLT: 2\n",
      "\n",
      "Explored 1 nodes (699 simplex iterations) in 0.07 seconds\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 4: 246.9 246.5 241.8 241.6 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.469000000000e+02, best bound 2.469000000000e+02, gap 0.0000%\n",
      "\n",
      "User-callback calls 124, time in user-callback 0.00 sec\n",
      "termination_status(model) = MathOptInterface.OPTIMAL\n",
      "objective_value(model) = 246.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "246.9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--- Write codes here to print your solutions\n",
    "optimize!(model)\n",
    "@show termination_status(model)\n",
    "@show objective_value(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/csv": [
       "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
       "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n"
      ],
      "text/plain": [
       "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\n",
       "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n",
       "1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"text/csv\", value.(x)) # could also display JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
